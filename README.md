## JLUie_MotionAnalysis唯一官方指定网站

![Matlab_R2017](https://img.shields.io/badge/MATLAB%40latest-R2017b-orange.svg)![PyPI - Python Version](https://img.shields.io/pypi/pyversions/Django.svg)

这里是```JLUie_MotionAnalysis```动作研究实验室的[数据库共享官网](https://tridu33.github.io/JLUie_MotionAnalysis/)，基于动作深度传感器```Kinect```，对人体动作数据进行实际采集，建立了一个适合国民身体特征的的动作数据库，在这个数据库里，对数据有需求的小伙伴们可以自行下载研究，同时欢迎有相关数据提供的同好在此基础上进行探索，欢迎同好们PR,丰富开源数据集。

最开始，这只是大创项目[基于机器学习的动作研究的内部模型训练数据库](https://tridu33.github.io/JLUie_MotionAnalysis/what-is-it.html)，但是使用数据骨骼点的时候，发现可开发的用途很多，团队就想数据共享，部分代码开源，方便有需求的小伙伴。

数据集中不但有静态骨骼点的**空间信息**，还有动态的**时间信息**（*Kinect*采样频率*30HZ*）！

要怎么使用我们的数据，就看你的想象力了！

你可以实现其他更多的功能，如果帧数不足，还可以针对骨骼点认为插值，使动作更流畅！

举些栗子：

* 用机器学习的方法进行动作识别，作为数据的训练集对算法进行训练
  * 人因动素分析，作业评价等工业工程相关的动作研究，作业评价，RULE模特法,
    * 虚拟现实和虚拟装配的数据实时采集，存储，
    * 导入虚拟建模软件绑定的骨骼点从而实现低成本实时动画制作，
* 不一而足，心有多大，梦有多远。

当然，如果你也有点小钱，买个*Kinect*自己在家玩耍，录入的数据能给我们反馈(pull request)一下下，丰富一下大家的动作数据库，开源共享，岂不美哉？

[动作数据使用教程和下载地址](https://tridu33.github.io/JLUie_MotionAnalysis/installation.html)

更多详情请见官网。





### The only officially designated website is JLUie_MotionAnalysis

![Matlab_R2017](https://img.shields.io/badge/MATLAB%40latest-R2017b-orange.svg)![PyPI - Python Version](https://img.shields.io/pypi/pyversions/Django.svg)

Here is `  JLUie_MotionAnalysis  ` [action research laboratory of Shared database website](https://tridu33.github.io/JLUie_MotionAnalysis/), based on the action depth sensor  ` device ` , actual human motion data acquisition, set up a suitable action of the national physical characteristics of database, the database, the data in need of friends can download research by oneself,At the same time, we welcome the data provided by you to explore on this basis, and welcome to PR to enrich the open source data set.

At first, this is just a big hit a project [internal model based on the action of machine learning research training database](https://tridu33.github.io/JLUie_MotionAnalysis/what-is-it.html), but using the data of bone point, found that can develop many USES, team wants to share data, part of the open source code, convenient friend with demand.

In the data set, there are not only static spatial information of bone points, but also dynamic time information.

How we use our data depends on your imagination!

You can do more than that, and if you don't have enough frames, you can even interpolate the bones to make the motion more fluid!

Hold some chestnuts:

\- the algorithm is trained as a training set of data by machine learning for motion recognition action research, activity evaluation, RULE model method, and other industrial engineering related activities

\- real-time data collection and storage of virtual reality and virtual assembly

\- import bone dots bound by virtual modeling software to achieve low-cost real-time animation

\- how big the heart is, how far the dream is.

Of course, if you have a little money to buy a *Kinect* and play at home, it would be nice if the data you input could give us some feedback (pull request), enrich everyone's action database and open source sharing.

[action data using tutorials and download address](https://tridu33.github.io/JLUie_MotionAnalysis/installation.html)

See the website at the top for more details.